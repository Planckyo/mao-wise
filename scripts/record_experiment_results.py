#!/usr/bin/env python3
"""
å®éªŒç»“æœè®°å½•è„šæœ¬

ä»CSV/Excelå¯¼å…¥å®éªŒç»“æœï¼Œè¿½åŠ åˆ°experiments.parquetï¼Œè‡ªåŠ¨å»é‡ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ”¯æŒCSVå’ŒExcelæ ¼å¼å¯¼å…¥
- åŸºäºexperiment_id/batch_id/plan_idä¸‰é”®å»é‡
- è‡ªåŠ¨æ•°æ®ç±»å‹è½¬æ¢å’ŒéªŒè¯
- å¢é‡è¿½åŠ åˆ°parquetæ–‡ä»¶
- å®Œæ•´çš„å¯¼å…¥æ—¥å¿—å’Œç»Ÿè®¡

ä½¿ç”¨ç¤ºä¾‹ï¼š
python scripts/record_experiment_results.py --file results/round1_results.xlsx
python scripts/record_experiment_results.py --file results/batch_results.csv --dry-run
"""

import argparse
import json
import sys
import pathlib
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import logging

# ç¡®ä¿èƒ½æ‰¾åˆ°maowiseåŒ…
REPO_ROOT = pathlib.Path(__file__).resolve().parent.parent
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

from maowise.utils.logger import logger

class ExperimentRecorder:
    """å®éªŒç»“æœè®°å½•å™¨"""
    
    def __init__(self, experiments_dir: str = "datasets/experiments"):
        self.experiments_dir = pathlib.Path(experiments_dir)
        self.experiments_dir.mkdir(parents=True, exist_ok=True)
        self.parquet_file = self.experiments_dir / "experiments.parquet"
        
        # å®šä¹‰æ ‡å‡†å­—æ®µå’Œæ•°æ®ç±»å‹
        self.required_fields = [
            'experiment_id', 'batch_id', 'plan_id', 'system',
            'measured_alpha', 'measured_epsilon'
        ]
        
        self.field_types = {
            'experiment_id': 'str',
            'batch_id': 'str', 
            'plan_id': 'str',
            'system': 'str',
            'substrate_alloy': 'str',
            'electrolyte_components_json': 'str',
            'voltage_V': 'float',
            'current_density_Adm2': 'float',
            'frequency_Hz': 'float',
            'duty_cycle_pct': 'float',
            'time_min': 'float',
            'temp_C': 'float',
            'pH': 'float',
            'post_treatment': 'str',
            'measured_alpha': 'float',
            'measured_epsilon': 'float',
            'hardness_HV': 'float',
            'roughness_Ra_um': 'float',
            'corrosion_rate_mmpy': 'float',
            'notes': 'str',
            'reviewer': 'str',
            'timestamp': 'str'
        }
    
    def _validate_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
        """éªŒè¯å’Œæ¸…ç†æ•°æ®"""
        errors = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        missing_fields = [f for f in self.required_fields if f not in df.columns]
        if missing_fields:
            errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
            return df, errors
        
        # æ•°æ®ç±»å‹è½¬æ¢
        for field, dtype in self.field_types.items():
            if field in df.columns:
                try:
                    if dtype == 'float':
                        df[field] = pd.to_numeric(df[field], errors='coerce')
                    elif dtype == 'str':
                        df[field] = df[field].astype(str).replace('nan', '')
                except Exception as e:
                    errors.append(f"å­—æ®µ {field} ç±»å‹è½¬æ¢å¤±è´¥: {e}")
        
        # éªŒè¯å…³é”®æ•°å€¼èŒƒå›´
        if 'measured_alpha' in df.columns:
            invalid_alpha = df[(df['measured_alpha'] < 0) | (df['measured_alpha'] > 1)].index
            if len(invalid_alpha) > 0:
                errors.append(f"measured_alpha è¶…å‡ºèŒƒå›´ [0,1]: è¡Œ {invalid_alpha.tolist()}")
        
        if 'measured_epsilon' in df.columns:
            invalid_epsilon = df[(df['measured_epsilon'] < 0) | (df['measured_epsilon'] > 2)].index
            if len(invalid_epsilon) > 0:
                errors.append(f"measured_epsilon è¶…å‡ºèŒƒå›´ [0,2]: è¡Œ {invalid_epsilon.tolist()}")
        
        # æ£€æŸ¥é‡å¤çš„ä¸»é”®
        key_columns = ['experiment_id', 'batch_id', 'plan_id']
        duplicates = df[df.duplicated(subset=key_columns, keep=False)]
        if len(duplicates) > 0:
            errors.append(f"å‘ç°é‡å¤è®°å½•: {len(duplicates)} æ¡")
        
        return df, errors
    
    def _load_existing_data(self) -> pd.DataFrame:
        """åŠ è½½ç°æœ‰å®éªŒæ•°æ®"""
        if self.parquet_file.exists():
            try:
                existing_df = pd.read_parquet(self.parquet_file)
                logger.info(f"åŠ è½½ç°æœ‰å®éªŒæ•°æ®: {len(existing_df)} æ¡è®°å½•")
                return existing_df
            except Exception as e:
                logger.error(f"åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}")
                return pd.DataFrame()
        else:
            logger.info("æœªæ‰¾åˆ°ç°æœ‰å®éªŒæ•°æ®ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return pd.DataFrame()
    
    def _deduplicate_records(self, new_df: pd.DataFrame, existing_df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:
        """å»é‡å¤„ç†"""
        key_columns = ['experiment_id', 'batch_id', 'plan_id']
        
        stats = {
            'total_new': len(new_df),
            'duplicates_internal': 0,
            'duplicates_existing': 0,
            'final_new': 0
        }
        
        # 1. å»é™¤æ–°æ•°æ®å†…éƒ¨é‡å¤
        if len(new_df) > 0:
            duplicates_internal = new_df.duplicated(subset=key_columns, keep='first')
            stats['duplicates_internal'] = duplicates_internal.sum()
            new_df_clean = new_df[~duplicates_internal].copy()
        else:
            new_df_clean = new_df.copy()
        
        # 2. å»é™¤ä¸ç°æœ‰æ•°æ®çš„é‡å¤
        if len(existing_df) > 0 and len(new_df_clean) > 0:
            # åˆ›å»ºå¤åˆé”®è¿›è¡Œæ¯”è¾ƒ
            existing_keys = existing_df[key_columns].apply(
                lambda x: f"{x['experiment_id']}|{x['batch_id']}|{x['plan_id']}", axis=1
            ).tolist()
            
            new_keys = new_df_clean[key_columns].apply(
                lambda x: f"{x['experiment_id']}|{x['batch_id']}|{x['plan_id']}", axis=1
            )
            
            duplicates_existing = new_keys.isin(existing_keys)
            stats['duplicates_existing'] = duplicates_existing.sum()
            final_new_df = new_df_clean[~duplicates_existing].copy()
        else:
            final_new_df = new_df_clean.copy()
        
        stats['final_new'] = len(final_new_df)
        
        return final_new_df, stats
    
    def import_from_file(self, file_path: str, dry_run: bool = False) -> Dict[str, Any]:
        """ä»æ–‡ä»¶å¯¼å…¥å®éªŒç»“æœ"""
        file_path = pathlib.Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # è¯»å–æ–‡ä»¶
        try:
            if file_path.suffix.lower() == '.csv':
                new_df = pd.read_csv(file_path, encoding='utf-8-sig')
            elif file_path.suffix.lower() in ['.xlsx', '.xls']:
                new_df = pd.read_excel(file_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")
            
            logger.info(f"æˆåŠŸè¯»å–æ–‡ä»¶ {file_path}: {len(new_df)} æ¡è®°å½•")
        except Exception as e:
            raise ValueError(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        
        # æ•°æ®éªŒè¯
        new_df, validation_errors = self._validate_data(new_df)
        if validation_errors:
            logger.error("æ•°æ®éªŒè¯å¤±è´¥:")
            for error in validation_errors:
                logger.error(f"  - {error}")
            raise ValueError("æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶")
        
        # åŠ è½½ç°æœ‰æ•°æ®
        existing_df = self._load_existing_data()
        
        # å»é‡å¤„ç†
        final_new_df, dedup_stats = self._deduplicate_records(new_df, existing_df)
        
        result = {
            'file_path': str(file_path),
            'import_time': datetime.now().isoformat(),
            'stats': dedup_stats,
            'validation_errors': validation_errors,
            'success': True
        }
        
        if dry_run:
            logger.info("DRY RUN - ä¸ä¼šå®é™…å†™å…¥æ•°æ®")
            result['dry_run'] = True
            return result
        
        # ä¿å­˜æ•°æ®
        if len(final_new_df) > 0:
            try:
                if len(existing_df) > 0:
                    # åˆå¹¶æ•°æ®
                    combined_df = pd.concat([existing_df, final_new_df], ignore_index=True)
                else:
                    combined_df = final_new_df
                
                # ä¿å­˜åˆ°parquet
                combined_df.to_parquet(self.parquet_file, index=False)
                
                # åˆ›å»ºå¤‡ä»½
                backup_file = self.experiments_dir / f"experiments_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet"
                combined_df.to_parquet(backup_file, index=False)
                
                logger.info(f"æˆåŠŸä¿å­˜å®éªŒæ•°æ®: {len(combined_df)} æ¡è®°å½•")
                logger.info(f"æ–°å¢è®°å½•: {len(final_new_df)} æ¡")
                logger.info(f"å¤‡ä»½æ–‡ä»¶: {backup_file}")
                
                result['total_records'] = len(combined_df)
                result['backup_file'] = str(backup_file)
                
            except Exception as e:
                logger.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
                result['success'] = False
                result['error'] = str(e)
        else:
            logger.info("æ²¡æœ‰æ–°è®°å½•éœ€è¦å¯¼å…¥")
            result['total_records'] = len(existing_df)
        
        return result
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """è·å–å®éªŒæ•°æ®æ‘˜è¦ç»Ÿè®¡"""
        if not self.parquet_file.exists():
            return {'total_records': 0, 'message': 'No experiment data found'}
        
        try:
            df = pd.read_parquet(self.parquet_file)
            
            stats = {
                'total_records': len(df),
                'unique_experiments': df['experiment_id'].nunique(),
                'unique_batches': df['batch_id'].nunique(),
                'systems': df['system'].value_counts().to_dict(),
                'date_range': {
                    'earliest': df['timestamp'].min() if 'timestamp' in df.columns else None,
                    'latest': df['timestamp'].max() if 'timestamp' in df.columns else None
                },
                'alpha_stats': {
                    'mean': float(df['measured_alpha'].mean()),
                    'std': float(df['measured_alpha'].std()),
                    'min': float(df['measured_alpha'].min()),
                    'max': float(df['measured_alpha'].max())
                } if 'measured_alpha' in df.columns else None,
                'epsilon_stats': {
                    'mean': float(df['measured_epsilon'].mean()),
                    'std': float(df['measured_epsilon'].std()),
                    'min': float(df['measured_epsilon'].min()),
                    'max': float(df['measured_epsilon'].max())
                } if 'measured_epsilon' in df.columns else None
            }
            
            return stats
        except Exception as e:
            logger.error(f"ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å®éªŒç»“æœè®°å½•è„šæœ¬ - å¯¼å…¥å®éªŒæ•°æ®åˆ°parquetæ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # å¯¼å…¥Excelæ–‡ä»¶
  python scripts/record_experiment_results.py --file results/round1_results.xlsx
  
  # å¯¼å…¥CSVæ–‡ä»¶ï¼ˆé¢„è§ˆæ¨¡å¼ï¼‰
  python scripts/record_experiment_results.py --file results/batch_results.csv --dry-run
  
  # æŸ¥çœ‹å½“å‰ç»Ÿè®¡ä¿¡æ¯
  python scripts/record_experiment_results.py --stats
        """
    )
    
    parser.add_argument("--file", 
                       type=str,
                       help="å®éªŒç»“æœæ–‡ä»¶è·¯å¾„ (CSVæˆ–Excel)")
    
    parser.add_argument("--dry-run", 
                       action="store_true",
                       help="é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…å†™å…¥æ•°æ®")
    
    parser.add_argument("--stats", 
                       action="store_true",
                       help="æ˜¾ç¤ºç°æœ‰å®éªŒæ•°æ®ç»Ÿè®¡ä¿¡æ¯")
    
    parser.add_argument("--experiments-dir", 
                       type=str,
                       default="datasets/experiments",
                       help="å®éªŒæ•°æ®ç›®å½• (é»˜è®¤: datasets/experiments)")
    
    args = parser.parse_args()
    
    try:
        recorder = ExperimentRecorder(args.experiments_dir)
        
        if args.stats:
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            print("ğŸ“Š å®éªŒæ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
            stats = recorder.get_summary_stats()
            
            if 'error' in stats:
                print(f"âŒ é”™è¯¯: {stats['error']}")
                return
            
            print(f"   - æ€»è®°å½•æ•°: {stats['total_records']}")
            print(f"   - ç‹¬ç‰¹å®éªŒ: {stats['unique_experiments']}")
            print(f"   - ç‹¬ç‰¹æ‰¹æ¬¡: {stats['unique_batches']}")
            
            if stats.get('systems'):
                print(f"   - ä½“ç³»åˆ†å¸ƒ:")
                for system, count in stats['systems'].items():
                    print(f"     * {system}: {count}")
            
            if stats.get('alpha_stats'):
                alpha_stats = stats['alpha_stats']
                print(f"   - Alphaç»Ÿè®¡: å‡å€¼={alpha_stats['mean']:.3f}, æ ‡å‡†å·®={alpha_stats['std']:.3f}")
            
            if stats.get('epsilon_stats'):
                epsilon_stats = stats['epsilon_stats']
                print(f"   - Epsilonç»Ÿè®¡: å‡å€¼={epsilon_stats['mean']:.3f}, æ ‡å‡†å·®={epsilon_stats['std']:.3f}")
            
            return
        
        if not args.file:
            parser.error("éœ€è¦æŒ‡å®š --file æˆ– --stats å‚æ•°")
        
        # å¯¼å…¥æ•°æ®
        print(f"ğŸ“ å¼€å§‹å¯¼å…¥å®éªŒç»“æœ...")
        print(f"   æ–‡ä»¶: {args.file}")
        print(f"   ç›®æ ‡ç›®å½•: {args.experiments_dir}")
        if args.dry_run:
            print("   æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (ä¸ä¼šå®é™…å†™å…¥)")
        
        result = recorder.import_from_file(args.file, dry_run=args.dry_run)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“‹ å¯¼å…¥ç»“æœ:")
        print(f"   - æ–‡ä»¶è®°å½•æ•°: {result['stats']['total_new']}")
        print(f"   - å†…éƒ¨é‡å¤: {result['stats']['duplicates_internal']}")
        print(f"   - ä¸ç°æœ‰é‡å¤: {result['stats']['duplicates_existing']}")
        print(f"   - æœ€ç»ˆæ–°å¢: {result['stats']['final_new']}")
        
        if result['success']:
            if not args.dry_run:
                print(f"   - æ€»è®°å½•æ•°: {result.get('total_records', '?')}")
                if result.get('backup_file'):
                    print(f"   - å¤‡ä»½æ–‡ä»¶: {result['backup_file']}")
            print("âœ… å¯¼å…¥æˆåŠŸ!")
        else:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            sys.exit(1)
        
        # æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡
        if not args.dry_run and result['stats']['final_new'] > 0:
            print(f"\nğŸ“Š æ›´æ–°åç»Ÿè®¡:")
            stats = recorder.get_summary_stats()
            print(f"   - æ€»è®°å½•æ•°: {stats['total_records']}")
            print(f"   - ç‹¬ç‰¹å®éªŒ: {stats['unique_experiments']}")
            print(f"   - ç‹¬ç‰¹æ‰¹æ¬¡: {stats['unique_batches']}")
        
    except Exception as e:
        logger.error(f"å¯¼å…¥å¤±è´¥: {e}")
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
