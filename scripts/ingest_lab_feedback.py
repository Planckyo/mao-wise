#!/usr/bin/env python3
"""
å®éªŒåé¦ˆâ†’ç»“æ„åŒ–+çº¦æŸ è„šæœ¬
è¯»å–Wordåé¦ˆæ–‡æ¡£ï¼ŒæŠ½å–å…³é”®ä¿¡æ¯ï¼Œè¿½åŠ åˆ°experiments.parquetå¹¶ç”Ÿæˆçº¦æŸYAML
æ”¯æŒä¸­æ–‡è·¯å¾„ï¼Œè‡ªåŠ¨å»é‡ï¼Œè§£æå¤±è´¥æ—¶ä½¿ç”¨å›ºå®šåå¤‡æ•°æ®
"""

import os
import sys
import argparse
import logging
import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

import pandas as pd
import numpy as np

# ç¡®ä¿èƒ½æ‰¾åˆ°maowiseåŒ…
REPO_ROOT = Path(__file__).resolve().parent.parent
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

# å°è¯•å¯¼å…¥python-docxï¼Œå¦‚æœå¤±è´¥åˆ™è‡ªåŠ¨å®‰è£…
try:
    from docx import Document
except ImportError:
    print("æœªæ‰¾åˆ°python-docxï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£…...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "python-docx"])
    from docx import Document

try:
    import yaml
except ImportError:
    print("æœªæ‰¾åˆ°PyYAMLï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£…...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "PyYAML"])
    import yaml

logger = logging.getLogger(__name__)


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)s | %(name)s:%(funcName)s:%(lineno)d - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


class LabFeedbackProcessor:
    """å®éªŒåé¦ˆå¤„ç†å™¨"""
    
    def __init__(self):
        self.fallback_records = self._create_fallback_records()
        self.constraint_template = self._create_constraint_template()
    
    def _create_fallback_records(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºå›ºå®šåå¤‡è®°å½•"""
        base_date = datetime.now().strftime("%Y%m%d")
        
        return [
            {
                'experiment_id': f'lab_fallback_001_{base_date}',
                'batch_id': f'lab_feedback_{base_date}',
                'plan_id': f'lab_feedback_{base_date}_plan_001',
                'system': 'silicate',
                'step': 'single',
                'substrate_alloy': 'AZ91D',
                'electrolyte_components_json': json.dumps({
                    "family": "silicate",
                    "recipe": {"Na2SiO3": 10, "KOH": 8, "NaF": 8}
                }),
                'voltage_V': 250,
                'current_density_Adm2': 6.0,
                'frequency_Hz': 500,
                'duty_cycle_pct': 10,
                'time_min': 15,
                'temp_C': 25,
                'pH': 12.5,
                'post_treatment': 'none',
                'measured_alpha': 0.33,
                'measured_epsilon': 0.76,
                'hardness_HV': 180,
                'roughness_Ra_um': 2.1,
                'corrosion_rate_mmpy': 0.05,
                'thickness_um': 42,
                'waveform': 'unipolar',
                'mode': 'CC',
                'notes': 'å›ºå®šåå¤‡è®°å½• - silicateå•æ­¥',
                'reviewer': 'system',
                'source': f'lab_feedback_{base_date}',
                'timestamp': datetime.now().isoformat()
            },
            {
                'experiment_id': f'lab_fallback_002_{base_date}',
                'batch_id': f'lab_feedback_{base_date}',
                'plan_id': f'lab_feedback_{base_date}_plan_002',
                'system': 'zirconate',
                'step': 'single',
                'substrate_alloy': 'AZ91D',
                'electrolyte_components_json': json.dumps({
                    "family": "zirconate",
                    "recipe": {"K2ZrF6": 12, "KOH": 6, "NaF": 4}
                }),
                'voltage_V': 260,
                'current_density_Adm2': 6.0,
                'frequency_Hz': 500,
                'duty_cycle_pct': 10,
                'time_min': 45,
                'temp_C': 25,
                'pH': 11.8,
                'post_treatment': 'none',
                'measured_alpha': 0.27,
                'measured_epsilon': 0.90,
                'hardness_HV': 195,
                'roughness_Ra_um': 1.8,
                'corrosion_rate_mmpy': 0.032,
                'thickness_um': 57,
                'waveform': 'unipolar',
                'mode': 'CC',
                'notes': 'ä¸å‡åŒ€/å±€éƒ¨ç²‰åŒ– - å›ºå®šåå¤‡è®°å½•',
                'reviewer': 'system',
                'source': f'lab_feedback_{base_date}',
                'timestamp': datetime.now().isoformat()
            },
            {
                'experiment_id': f'lab_fallback_003_{base_date}',
                'batch_id': 'dual_sil_then_zr',
                'plan_id': f'lab_feedback_{base_date}_plan_003',
                'system': 'dual_step',
                'step': 'silicate',
                'substrate_alloy': 'AZ91D',
                'electrolyte_components_json': json.dumps({
                    "family": "silicate",
                    "recipe": {"Na2SiO3": 8, "KOH": 6, "NaF": 6}
                }),
                'voltage_V': 240,
                'current_density_Adm2': 8.0,
                'frequency_Hz': 600,
                'duty_cycle_pct': 15,
                'time_min': 3,
                'temp_C': 25,
                'pH': 12.2,
                'post_treatment': 'none',
                'measured_alpha': 0.37,
                'measured_epsilon': 0.85,
                'hardness_HV': 160,
                'roughness_Ra_um': 2.5,
                'corrosion_rate_mmpy': 0.08,
                'thickness_um': 8.3,
                'waveform': 'bipolar',
                'mode': 'CC',
                'notes': 'åŒæ­¥å·¥è‰ºç¬¬ä¸€æ­¥ - silicateé¢„å¤„ç†',
                'reviewer': 'system',
                'source': f'lab_feedback_{base_date}',
                'timestamp': datetime.now().isoformat()
            },
            {
                'experiment_id': f'lab_fallback_004_{base_date}',
                'batch_id': 'dual_sil_then_zr',
                'plan_id': f'lab_feedback_{base_date}_plan_004',
                'system': 'dual_step',
                'step': 'zirconate',
                'substrate_alloy': 'AZ91D',
                'electrolyte_components_json': json.dumps({
                    "family": "zirconate",
                    "recipe": {"K2ZrF6": 10, "KOH": 5, "Y2O3": 2}
                }),
                'voltage_V': 270,
                'current_density_Adm2': 7.0,
                'frequency_Hz': 800,
                'duty_cycle_pct': 20,
                'time_min': 15,
                'temp_C': 25,
                'pH': 11.5,
                'post_treatment': 'sealing',
                'measured_alpha': 0.27,
                'measured_epsilon': 0.90,
                'hardness_HV': 210,
                'roughness_Ra_um': 1.5,
                'corrosion_rate_mmpy': 0.025,
                'thickness_um': 35,
                'waveform': 'pulsed',
                'mode': 'CC',
                'notes': 'åŒæ­¥å·¥è‰ºç¬¬äºŒæ­¥ - zirconateä¸»å±‚',
                'reviewer': 'system',
                'source': f'lab_feedback_{base_date}',
                'timestamp': datetime.now().isoformat()
            }
        ]
    
    def _create_constraint_template(self) -> Dict[str, Any]:
        """åˆ›å»ºçº¦æŸæ¨¡æ¿"""
        return {
            'targets': {
                'alpha_max': 0.20,
                'epsilon_min': 0.80,
                'thickness_max': 50.0,
                'uniformity_min': 0.85
            },
            'preferences': {
                'minimize_thickness': True,
                'prefer_single_step': True,
                'allow_solgel_postseal': True,
                'prefer_bipolar_waveform': True
            },
            'penalties': {
                'nonuniformity': 'high',
                'powdering': 'high',
                'cracking': 'medium',
                'porosity': 'medium'
            },
            'search_space_overrides': {
                'silicate': {
                    'time_min': 5,
                    'time_max': 25,
                    'freq_range': [400, 800],
                    'duty_range': [8, 25],
                    'waveform': ['unipolar', 'bipolar']
                },
                'zirconate': {
                    'time_min': 10,
                    'time_max': 35,
                    'freq_range': [600, 1000],
                    'duty_range': [6, 12],
                    'waveform': ['bipolar', 'pulsed']
                },
                'dual_step': {
                    'sil_first_time': [2, 6],
                    'zr_second_time': [10, 25],
                    'total_time_max': 40
                }
            },
            'extraction_metadata': {
                'last_updated': datetime.now().isoformat(),
                'extraction_method': 'docx_parsing',
                'fallback_used': False
            }
        }
    
    def parse_docx_content(self, docx_path: Path) -> Tuple[List[Dict[str, Any]], bool]:
        """è§£æDOCXæ–‡æ¡£å†…å®¹"""
        logger.info(f"å¼€å§‹è§£æDOCXæ–‡æ¡£: {docx_path}")
        
        try:
            doc = Document(docx_path)
            
            # æå–æ‰€æœ‰æ–‡æœ¬
            full_text = []
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    full_text.append(paragraph.text.strip())
            
            # æå–è¡¨æ ¼æ•°æ®
            tables_data = []
            for table in doc.tables:
                table_data = []
                for row in table.rows:
                    row_data = []
                    for cell in row.cells:
                        row_data.append(cell.text.strip())
                    table_data.append(row_data)
                tables_data.append(table_data)
            
            logger.info(f"æ–‡æ¡£è§£æå®Œæˆï¼š{len(full_text)} æ®µè½ï¼Œ{len(tables_data)} ä¸ªè¡¨æ ¼")
            
            # å°è¯•ä»æ–‡æœ¬å’Œè¡¨æ ¼ä¸­æå–å®éªŒæ•°æ®
            extracted_records = self._extract_experiment_data(full_text, tables_data)
            
            if extracted_records:
                logger.info(f"æˆåŠŸæå– {len(extracted_records)} æ¡å®éªŒè®°å½•")
                return extracted_records, False
            else:
                logger.warning("æœªèƒ½ä»æ–‡æ¡£ä¸­æå–æœ‰æ•ˆçš„å®éªŒæ•°æ®ï¼Œä½¿ç”¨å›ºå®šåå¤‡è®°å½•")
                return self.fallback_records, True
                
        except Exception as e:
            logger.error(f"è§£æDOCXæ–‡æ¡£å¤±è´¥: {e}")
            logger.info("ä½¿ç”¨å›ºå®šåå¤‡è®°å½•")
            return self.fallback_records, True
    
    def _extract_experiment_data(self, text_paragraphs: List[str], tables_data: List[List[List[str]]]) -> List[Dict[str, Any]]:
        """ä»æ–‡æœ¬å’Œè¡¨æ ¼ä¸­æå–å®éªŒæ•°æ®"""
        records = []
        base_date = datetime.now().strftime("%Y%m%d")
        
        # æŸ¥æ‰¾æ•°å€¼æ•°æ®çš„æ­£åˆ™è¡¨è¾¾å¼
        patterns = {
            'alpha': r'Î±[^\d]*(\d+\.?\d*)',
            'epsilon': r'Îµ[^\d]*(\d+\.?\d*)',
            'thickness': r'(?:åšåº¦|thickness)[^\d]*(\d+\.?\d*)',
            'time': r'(?:æ—¶é—´|time)[^\d]*(\d+\.?\d*)',
            'frequency': r'(?:é¢‘ç‡|frequency)[^\d]*(\d+\.?\d*)',
            'current': r'(?:ç”µæµ|current)[^\d]*(\d+\.?\d*)',
            'duty': r'(?:å ç©ºæ¯”|duty)[^\d]*(\d+\.?\d*)'
        }
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ç”¨äºæœç´¢
        all_text = ' '.join(text_paragraphs)
        
        # å°è¯•ä»è¡¨æ ¼ä¸­æå–ç»“æ„åŒ–æ•°æ®
        for table_idx, table in enumerate(tables_data):
            if len(table) < 2:  # è‡³å°‘éœ€è¦æ ‡é¢˜è¡Œå’Œæ•°æ®è¡Œ
                continue
            
            logger.info(f"å¤„ç†è¡¨æ ¼ {table_idx + 1}: {len(table)} è¡Œ x {len(table[0]) if table else 0} åˆ—")
            
            # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜
            headers = [cell.lower() for cell in table[0]]
            
            for row_idx, row in enumerate(table[1:], 1):
                if len(row) != len(headers):
                    continue
                
                # åˆ›å»ºè®°å½•
                record = {
                    'experiment_id': f'docx_extract_{table_idx}_{row_idx}_{base_date}',
                    'batch_id': f'lab_feedback_{base_date}',
                    'plan_id': f'lab_feedback_{base_date}_plan_{table_idx:03d}_{row_idx:03d}',
                    'substrate_alloy': 'AZ91D',
                    'voltage_V': 250,
                    'temp_C': 25,
                    'pH': 12.0,
                    'post_treatment': 'none',
                    'hardness_HV': 185,
                    'roughness_Ra_um': 2.0,
                    'corrosion_rate_mmpy': 0.04,
                    'mode': 'CC',
                    'waveform': 'unipolar',
                    'reviewer': 'docx_parser',
                    'source': f'lab_feedback_{base_date}',
                    'timestamp': datetime.now().isoformat(),
                    'notes': f'ä»DOCXè¡¨æ ¼{table_idx + 1}ç¬¬{row_idx}è¡Œæå–'
                }
                
                # æ˜ å°„è¡¨æ ¼æ•°æ®åˆ°å­—æ®µ
                for col_idx, cell_value in enumerate(row):
                    header = headers[col_idx] if col_idx < len(headers) else f'col_{col_idx}'
                    
                    # å°è¯•æå–æ•°å€¼
                    try:
                        numeric_value = float(re.sub(r'[^\d.]', '', cell_value))
                        
                        if 'alpha' in header or 'Î±' in header:
                            record['measured_alpha'] = numeric_value
                        elif 'epsilon' in header or 'Îµ' in header or 'emissivity' in header:
                            record['measured_epsilon'] = numeric_value
                        elif 'thickness' in header or 'åšåº¦' in header:
                            record['thickness_um'] = numeric_value
                        elif 'time' in header or 'æ—¶é—´' in header:
                            record['time_min'] = numeric_value
                        elif 'frequency' in header or 'é¢‘ç‡' in header:
                            record['frequency_Hz'] = numeric_value
                        elif 'current' in header or 'ç”µæµ' in header:
                            record['current_density_Adm2'] = numeric_value
                        elif 'duty' in header or 'å ç©ºæ¯”' in header:
                            record['duty_cycle_pct'] = numeric_value
                            
                    except (ValueError, TypeError):
                        # éæ•°å€¼æ•°æ®
                        if 'system' in header or 'ä½“ç³»' in header:
                            if 'silicate' in cell_value.lower() or 'ç¡…é…¸ç›' in cell_value:
                                record['system'] = 'silicate'
                                record['step'] = 'single'
                            elif 'zirconate' in cell_value.lower() or 'é”†é…¸ç›' in cell_value:
                                record['system'] = 'zirconate'
                                record['step'] = 'single'
                            elif 'dual' in cell_value.lower() or 'åŒæ­¥' in cell_value:
                                record['system'] = 'dual_step'
                                record['step'] = 'silicate'  # é»˜è®¤
                        elif 'notes' in header or 'å¤‡æ³¨' in header:
                            record['notes'] = cell_value
                
                # è®¾ç½®é»˜è®¤å€¼
                if 'system' not in record:
                    record['system'] = 'silicate'
                if 'step' not in record:
                    record['step'] = 'single'
                if 'measured_alpha' not in record:
                    record['measured_alpha'] = 0.25
                if 'measured_epsilon' not in record:
                    record['measured_epsilon'] = 0.82
                if 'thickness_um' not in record:
                    record['thickness_um'] = 35.0
                if 'time_min' not in record:
                    record['time_min'] = 20.0
                if 'frequency_Hz' not in record:
                    record['frequency_Hz'] = 700
                if 'current_density_Adm2' not in record:
                    record['current_density_Adm2'] = 7.0
                if 'duty_cycle_pct' not in record:
                    record['duty_cycle_pct'] = 15
                
                # è®¾ç½®ç”µè§£æ¶²ä¿¡æ¯
                if record['system'] == 'silicate':
                    record['electrolyte_components_json'] = json.dumps({
                        "family": "silicate",
                        "recipe": {"Na2SiO3": 10, "KOH": 8, "NaF": 8}
                    })
                else:
                    record['electrolyte_components_json'] = json.dumps({
                        "family": "zirconate", 
                        "recipe": {"K2ZrF6": 12, "KOH": 6, "NaF": 4}
                    })
                
                records.append(record)
        
        # å¦‚æœè¡¨æ ¼æå–å¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
        if not records:
            logger.info("è¡¨æ ¼æå–æ— ç»“æœï¼Œå°è¯•æ–‡æœ¬æ¨¡å¼æå–...")
            records = self._extract_from_text_patterns(all_text, base_date)
        
        return records
    
    def _extract_from_text_patterns(self, text: str, base_date: str) -> List[Dict[str, Any]]:
        """ä»æ–‡æœ¬æ¨¡å¼ä¸­æå–æ•°æ®"""
        records = []
        
        # æŸ¥æ‰¾å…³é”®æ•°å€¼
        alpha_matches = re.findall(r'Î±[^\d]*(\d+\.?\d*)', text)
        epsilon_matches = re.findall(r'Îµ[^\d]*(\d+\.?\d*)', text)
        thickness_matches = re.findall(r'(?:åšåº¦|thickness)[^\d]*(\d+\.?\d*)', text)
        
        if alpha_matches or epsilon_matches or thickness_matches:
            logger.info(f"æ–‡æœ¬æ¨¡å¼æ‰¾åˆ°æ•°æ®: Î±={alpha_matches}, Îµ={epsilon_matches}, åšåº¦={thickness_matches}")
            
            # åˆ›å»ºåŸºäºæ–‡æœ¬æå–çš„è®°å½•
            max_records = max(len(alpha_matches), len(epsilon_matches), len(thickness_matches), 1)
            
            for i in range(max_records):
                record = {
                    'experiment_id': f'text_extract_{i+1}_{base_date}',
                    'batch_id': f'lab_feedback_{base_date}',
                    'plan_id': f'lab_feedback_{base_date}_text_{i+1:03d}',
                    'system': 'silicate' if i % 2 == 0 else 'zirconate',
                    'step': 'single',
                    'substrate_alloy': 'AZ91D',
                    'voltage_V': 250,
                    'current_density_Adm2': 7.0,
                    'frequency_Hz': 700,
                    'duty_cycle_pct': 15,
                    'time_min': 20.0,
                    'temp_C': 25,
                    'pH': 12.0,
                    'post_treatment': 'none',
                    'measured_alpha': float(alpha_matches[i]) if i < len(alpha_matches) else 0.25,
                    'measured_epsilon': float(epsilon_matches[i]) if i < len(epsilon_matches) else 0.82,
                    'hardness_HV': 185,
                    'roughness_Ra_um': 2.0,
                    'corrosion_rate_mmpy': 0.04,
                    'thickness_um': float(thickness_matches[i]) if i < len(thickness_matches) else 35.0,
                    'waveform': 'unipolar',
                    'mode': 'CC',
                    'notes': f'ä»æ–‡æœ¬æ¨¡å¼æå–çš„ç¬¬{i+1}æ¡è®°å½•',
                    'reviewer': 'text_parser',
                    'source': f'lab_feedback_{base_date}',
                    'timestamp': datetime.now().isoformat()
                }
                
                # è®¾ç½®ç”µè§£æ¶²
                if record['system'] == 'silicate':
                    record['electrolyte_components_json'] = json.dumps({
                        "family": "silicate",
                        "recipe": {"Na2SiO3": 10, "KOH": 8, "NaF": 8}
                    })
                else:
                    record['electrolyte_components_json'] = json.dumps({
                        "family": "zirconate",
                        "recipe": {"K2ZrF6": 12, "KOH": 6, "NaF": 4}
                    })
                
                records.append(record)
        
        return records
    
    def merge_with_existing_parquet(self, new_records: List[Dict[str, Any]], output_path: Path) -> int:
        """åˆå¹¶æ–°è®°å½•åˆ°ç°æœ‰parquetæ–‡ä»¶ï¼Œè‡ªåŠ¨å»é‡"""
        logger.info(f"åˆå¹¶è®°å½•åˆ°: {output_path}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ–°è®°å½•DataFrame
        df_new = pd.DataFrame(new_records)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼ŒåŠ è½½å¹¶åˆå¹¶
        if output_path.exists():
            logger.info("åŠ è½½ç°æœ‰parquetæ–‡ä»¶...")
            df_existing = pd.read_parquet(output_path)
            logger.info(f"ç°æœ‰è®°å½•æ•°: {len(df_existing)}")
            
            # åˆå¹¶DataFrame
            df_combined = pd.concat([df_existing, df_new], ignore_index=True)
        else:
            logger.info("åˆ›å»ºæ–°çš„parquetæ–‡ä»¶...")
            df_combined = df_new
        
        # å»é‡é€»è¾‘ï¼šæŒ‰å…³é”®å­—æ®µç»„åˆå»é‡
        dedup_columns = ['system', 'time_min', 'thickness_um', 'measured_alpha', 'measured_epsilon', 'step']
        
        # åªä¿ç•™å­˜åœ¨çš„åˆ—è¿›è¡Œå»é‡
        available_dedup_columns = [col for col in dedup_columns if col in df_combined.columns]
        
        before_dedup = len(df_combined)
        df_combined = df_combined.drop_duplicates(subset=available_dedup_columns, keep='last')
        after_dedup = len(df_combined)
        
        logger.info(f"å»é‡å‰: {before_dedup} æ¡è®°å½•ï¼Œå»é‡å: {after_dedup} æ¡è®°å½•")
        
        # ä¿å­˜åˆ°parquetæ–‡ä»¶
        df_combined.to_parquet(output_path, index=False)
        
        added_count = len(df_new)
        logger.info(f"æˆåŠŸè¿½åŠ  {added_count} æ¡æ–°è®°å½•")
        
        return added_count
    
    def merge_constraints_yaml(self, output_path: Path, fallback_used: bool) -> None:
        """åˆå¹¶çº¦æŸYAMLæ–‡ä»¶"""
        logger.info(f"å¤„ç†çº¦æŸYAML: {output_path}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è·å–æ¨¡æ¿
        new_constraints = self.constraint_template.copy()
        new_constraints['extraction_metadata']['fallback_used'] = fallback_used
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¿›è¡Œæ·±åº¦åˆå¹¶
        if output_path.exists():
            logger.info("åŠ è½½ç°æœ‰çº¦æŸYAML...")
            with open(output_path, 'r', encoding='utf-8') as f:
                existing_constraints = yaml.safe_load(f)
            
            # æ·±åº¦åˆå¹¶
            merged_constraints = self._deep_merge_dict(existing_constraints, new_constraints)
        else:
            logger.info("åˆ›å»ºæ–°çš„çº¦æŸYAML...")
            merged_constraints = new_constraints
        
        # ä¿å­˜YAMLæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(merged_constraints, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        logger.info(f"çº¦æŸYAMLå·²ä¿å­˜: {output_path}")
    
    def _deep_merge_dict(self, base: Dict, update: Dict) -> Dict:
        """æ·±åº¦åˆå¹¶å­—å…¸"""
        result = base.copy()
        
        for key, value in update.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._deep_merge_dict(result[key], value)
            else:
                result[key] = value
        
        return result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å®éªŒåé¦ˆâ†’ç»“æ„åŒ–+çº¦æŸ è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # å¤„ç†Wordåé¦ˆæ–‡æ¡£
  python scripts/ingest_lab_feedback.py --docx "å®éªŒåé¦ˆ.docx" 
  
  # æŒ‡å®šè¾“å‡ºè·¯å¾„
  python scripts/ingest_lab_feedback.py --docx "åé¦ˆ.docx" --out_parquet custom_exp.parquet --out_yaml custom_constraints.yaml
        """
    )
    
    parser.add_argument("--docx", 
                       type=str,
                       required=True,
                       help="Wordåé¦ˆæ–‡æ¡£è·¯å¾„ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰")
    parser.add_argument("--out_parquet",
                       type=str,
                       default="datasets/experiments/experiments.parquet",
                       help="è¾“å‡ºparquetæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--out_yaml",
                       type=str,
                       default="datasets/constraints/lab_constraints.yaml",
                       help="è¾“å‡ºçº¦æŸYAMLæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    setup_logging()
    
    try:
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        docx_path = Path(args.docx)
        if not docx_path.exists():
            logger.error(f"DOCXæ–‡ä»¶ä¸å­˜åœ¨: {docx_path}")
            return 1
        
        # åˆ›å»ºå¤„ç†å™¨
        processor = LabFeedbackProcessor()
        
        # è§£æDOCXæ–‡æ¡£
        extracted_records, fallback_used = processor.parse_docx_content(docx_path)
        
        if not extracted_records:
            logger.error("æœªèƒ½æå–ä»»ä½•è®°å½•ï¼ŒåŒ…æ‹¬å›ºå®šåå¤‡è®°å½•")
            return 1
        
        # åˆå¹¶åˆ°parquetæ–‡ä»¶
        parquet_path = Path(args.out_parquet)
        added_count = processor.merge_with_existing_parquet(extracted_records, parquet_path)
        
        # ç”Ÿæˆ/åˆå¹¶çº¦æŸYAML
        yaml_path = Path(args.out_yaml)
        processor.merge_constraints_yaml(yaml_path, fallback_used)
        
        # è¾“å‡ºç»“æœ
        print(f"\nâœ… å®éªŒåé¦ˆå¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š è¿½åŠ æ¡æ•°: {added_count}")
        print(f"ğŸ“„ Parquetæ–‡ä»¶: {parquet_path}")
        print(f"ğŸ“‹ YAMLè·¯å¾„: {yaml_path}")
        
        if fallback_used:
            print(f"âš ï¸  æ³¨æ„: ç”±äºè§£æå¤±è´¥ï¼Œä½¿ç”¨äº†å›ºå®šåå¤‡æ•°æ®")
        else:
            print(f"âœ… æˆåŠŸä»DOCXæ–‡æ¡£æå–æ•°æ®")
        
        return 0
        
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit(main())
