#!/usr/bin/env python3
"""
æ²»ç†åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import sys
import time
import json
import asyncio
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from maowise.llm.client import llm_chat, get_usage_stats
from maowise.utils.config import load_config
from maowise.utils.sanitizer import sanitize_text, sanitize_dict, create_debug_info
from maowise.utils.logger import logger


def test_rate_limiting():
    """æµ‹è¯•é€Ÿç‡é™åˆ¶"""
    print("\n" + "="*60)
    print("ğŸš¦ æµ‹è¯•é€Ÿç‡é™åˆ¶")
    print("="*60)
    
    cfg = load_config()
    rpm = cfg.get("llm", {}).get("limits", {}).get("max_requests_per_minute", 100)
    
    print(f"é…ç½®çš„RPMé™åˆ¶: {rpm}")
    
    # å¿«é€Ÿå‘é€å¤šä¸ªè¯·æ±‚æµ‹è¯•é€Ÿç‡é™åˆ¶
    messages = [{"role": "user", "content": "Hello, this is a test message."}]
    
    success_count = 0
    rate_limited_count = 0
    
    print("å‘é€10ä¸ªå¿«é€Ÿè¯·æ±‚...")
    start_time = time.time()
    
    for i in range(10):
        try:
            response = llm_chat(messages, use_cache=False)
            if "rate_limited" in response.get("usage", {}).get("model", ""):
                rate_limited_count += 1
                print(f"  è¯·æ±‚ {i+1}: é€Ÿç‡é™åˆ¶è§¦å‘ âš ï¸")
            else:
                success_count += 1
                print(f"  è¯·æ±‚ {i+1}: æˆåŠŸ âœ…")
        except Exception as e:
            print(f"  è¯·æ±‚ {i+1}: é”™è¯¯ - {e}")
    
    duration = time.time() - start_time
    print(f"\nç»“æœ:")
    print(f"  æˆåŠŸè¯·æ±‚: {success_count}")
    print(f"  é€Ÿç‡é™åˆ¶: {rate_limited_count}")
    print(f"  æ€»è€—æ—¶: {duration:.2f}s")
    
    if rate_limited_count > 0:
        print("âœ… é€Ÿç‡é™åˆ¶åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        print("â„¹ï¸ æœªè§¦å‘é€Ÿç‡é™åˆ¶ï¼ˆå¯èƒ½RPMè®¾ç½®è¾ƒé«˜ï¼‰")


def test_usage_tracking():
    """æµ‹è¯•ä½¿ç”¨ç»Ÿè®¡"""
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ä½¿ç”¨ç»Ÿè®¡")
    print("="*60)
    
    cfg = load_config()
    usage_file = Path(cfg.get("llm", {}).get("usage_tracking", {}).get("log_file", "datasets/cache/llm_usage.csv"))
    
    print(f"ä½¿ç”¨ç»Ÿè®¡æ–‡ä»¶: {usage_file}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if usage_file.exists():
        print("âœ… ä½¿ç”¨ç»Ÿè®¡æ–‡ä»¶å­˜åœ¨")
        
        # è¯»å–æœ€åå‡ è¡Œ
        try:
            with open(usage_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            print(f"æ–‡ä»¶è¡Œæ•°: {len(lines)}")
            
            if len(lines) > 1:
                print("æœ€è¿‘çš„è®°å½•:")
                for line in lines[-3:]:  # æ˜¾ç¤ºæœ€å3è¡Œ
                    print(f"  {line.strip()}")
            else:
                print("æ–‡ä»¶ä¸ºç©ºæˆ–åªæœ‰è¡¨å¤´")
                
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
    else:
        print("âŒ ä½¿ç”¨ç»Ÿè®¡æ–‡ä»¶ä¸å­˜åœ¨")
    
    # å‘é€ä¸€ä¸ªè¯·æ±‚ä»¥è§¦å‘ç»Ÿè®¡è®°å½•
    print("\nå‘é€æµ‹è¯•è¯·æ±‚ä»¥è§¦å‘ç»Ÿè®¡...")
    messages = [{"role": "user", "content": "Test usage tracking"}]
    
    try:
        response = llm_chat(messages)
        print("âœ… è¯·æ±‚æˆåŠŸ")
        
        # ç­‰å¾…å†™å…¥
        time.sleep(0.1)
        
        # å†æ¬¡æ£€æŸ¥æ–‡ä»¶
        if usage_file.exists():
            with open(usage_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            print(f"æ›´æ–°åæ–‡ä»¶è¡Œæ•°: {len(lines)}")
            
            if len(lines) > 1:
                print("æœ€æ–°è®°å½•:")
                print(f"  {lines[-1].strip()}")
        
    except Exception as e:
        print(f"æµ‹è¯•è¯·æ±‚å¤±è´¥: {e}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\nè·å–ä½¿ç”¨ç»Ÿè®¡...")
    try:
        stats = get_usage_stats(days=1)
        print(f"ç»Ÿè®¡ä¿¡æ¯: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    except Exception as e:
        print(f"è·å–ç»Ÿè®¡å¤±è´¥: {e}")


def test_log_sanitization():
    """æµ‹è¯•æ—¥å¿—è„±æ•"""
    print("\n" + "="*60)
    print("ğŸ”’ æµ‹è¯•æ—¥å¿—è„±æ•")
    print("="*60)
    
    # æµ‹è¯•æ–‡æœ¬è„±æ•
    test_cases = [
        "My API key is sk-1234567890abcdefghijklmnopqrstuvwxyz",
        "Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIn0",
        "File path: C:\\Users\\Admin\\Documents\\secret.key",
        "Unix path: /home/user/.ssh/id_rsa",
        "Password: mypassword123",
        "Normal text without sensitive info"
    ]
    
    print("æ–‡æœ¬è„±æ•æµ‹è¯•:")
    for i, text in enumerate(test_cases, 1):
        sanitized = sanitize_text(text)
        print(f"  {i}. åŸæ–‡: {text}")
        print(f"     è„±æ•: {sanitized}")
        print()
    
    # æµ‹è¯•å­—å…¸è„±æ•
    test_dict = {
        "api_key": "sk-1234567890abcdefghijklmnopqrstuvwxyz",
        "secret": "mysecret123",
        "normal_field": "normal value",
        "nested": {
            "token": "Bearer abc123",
            "safe_data": "safe value"
        },
        "list_data": [
            "normal item",
            "api_key=sk-abcdef123456789",
            {"password": "secret123"}
        ]
    }
    
    print("å­—å…¸è„±æ•æµ‹è¯•:")
    print("åŸå§‹å­—å…¸:")
    print(json.dumps(test_dict, indent=2, ensure_ascii=False))
    
    sanitized_dict = sanitize_dict(test_dict)
    print("\nè„±æ•åå­—å…¸:")
    print(json.dumps(sanitized_dict, indent=2, ensure_ascii=False))


def test_debug_info():
    """æµ‹è¯•è°ƒè¯•ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ğŸ› æµ‹è¯•è°ƒè¯•ä¿¡æ¯")
    print("="*60)
    
    # æµ‹è¯•åŸºæœ¬è°ƒè¯•ä¿¡æ¯
    debug_info = create_debug_info(include_full_env=False)
    print("åŸºæœ¬è°ƒè¯•ä¿¡æ¯:")
    print(json.dumps(debug_info, indent=2, ensure_ascii=False))
    
    print("\nå®Œæ•´è°ƒè¯•ä¿¡æ¯:")
    full_debug_info = create_debug_info(include_full_env=True)
    print(json.dumps(full_debug_info, indent=2, ensure_ascii=False))


def test_concurrent_limits():
    """æµ‹è¯•å¹¶å‘é™åˆ¶"""
    print("\n" + "="*60)
    print("ğŸ”€ æµ‹è¯•å¹¶å‘é™åˆ¶")
    print("="*60)
    
    cfg = load_config()
    max_concurrent = cfg.get("llm", {}).get("limits", {}).get("max_concurrent_requests", 5)
    
    print(f"é…ç½®çš„å¹¶å‘é™åˆ¶: {max_concurrent}")
    
    async def make_request(request_id):
        """å¼‚æ­¥è¯·æ±‚å‡½æ•°"""
        print(f"  è¯·æ±‚ {request_id} å¼€å§‹")
        start_time = time.time()
        
        try:
            messages = [{"role": "user", "content": f"Concurrent test request {request_id}"}]
            response = llm_chat(messages, use_cache=False)
            duration = time.time() - start_time
            print(f"  è¯·æ±‚ {request_id} å®Œæˆ ({duration:.2f}s) âœ…")
            return True
        except Exception as e:
            duration = time.time() - start_time
            print(f"  è¯·æ±‚ {request_id} å¤±è´¥ ({duration:.2f}s): {e}")
            return False
    
    async def test_concurrent():
        """å¹¶å‘æµ‹è¯•"""
        print(f"åŒæ—¶å‘é€ {max_concurrent + 2} ä¸ªè¯·æ±‚...")
        
        tasks = []
        for i in range(max_concurrent + 2):
            task = asyncio.create_task(make_request(i + 1))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        success_count = sum(1 for r in results if r is True)
        print(f"\nç»“æœ: {success_count}/{len(tasks)} è¯·æ±‚æˆåŠŸ")
    
    # è¿è¡Œå¹¶å‘æµ‹è¯•
    try:
        asyncio.run(test_concurrent())
        print("âœ… å¹¶å‘é™åˆ¶æµ‹è¯•å®Œæˆ")
    except Exception as e:
        print(f"å¹¶å‘æµ‹è¯•å¤±è´¥: {e}")


def test_cost_tracking():
    """æµ‹è¯•æˆæœ¬è·Ÿè¸ª"""
    print("\n" + "="*60)
    print("ğŸ’° æµ‹è¯•æˆæœ¬è·Ÿè¸ª")
    print("="*60)
    
    # å‘é€å‡ ä¸ªä¸åŒé•¿åº¦çš„è¯·æ±‚æ¥æµ‹è¯•æˆæœ¬è®¡ç®—
    test_messages = [
        [{"role": "user", "content": "Short"}],
        [{"role": "user", "content": "This is a medium length message for testing cost calculation."}],
        [{"role": "user", "content": "This is a very long message designed to test the cost calculation functionality. " * 10}]
    ]
    
    total_cost = 0.0
    
    for i, messages in enumerate(test_messages, 1):
        print(f"\næµ‹è¯•è¯·æ±‚ {i} (é•¿åº¦: {len(messages[0]['content'])} å­—ç¬¦)...")
        
        try:
            response = llm_chat(messages, use_cache=False)
            usage = response.get("usage", {})
            
            print(f"  Tokenä½¿ç”¨: {usage}")
            
            # ç®€å•æˆæœ¬ä¼°ç®—ï¼ˆå‡è®¾ä½¿ç”¨gpt-4o-miniï¼‰
            prompt_tokens = usage.get("prompt_tokens", 0)
            completion_tokens = usage.get("completion_tokens", 0)
            estimated_cost = prompt_tokens * 0.00015/1000 + completion_tokens * 0.0006/1000
            total_cost += estimated_cost
            
            print(f"  ä¼°ç®—æˆæœ¬: ${estimated_cost:.6f}")
            
        except Exception as e:
            print(f"  è¯·æ±‚å¤±è´¥: {e}")
    
    print(f"\næ€»ä¼°ç®—æˆæœ¬: ${total_cost:.6f}")
    
    # æ£€æŸ¥æ¯æ—¥é™åˆ¶
    cfg = load_config()
    daily_limit = cfg.get("llm", {}).get("limits", {}).get("cost_limit_per_day_usd", 10.0)
    print(f"æ¯æ—¥æˆæœ¬é™åˆ¶: ${daily_limit}")
    
    if total_cost < daily_limit:
        print("âœ… åœ¨æˆæœ¬é™åˆ¶å†…")
    else:
        print("âš ï¸ è¶…å‡ºæˆæœ¬é™åˆ¶")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ­ MAO-Wise æ²»ç†åŠŸèƒ½æµ‹è¯•")
    print("æµ‹è¯•é€Ÿç‡/æˆæœ¬æ§åˆ¶ã€æ—¥å¿—è„±æ•å’Œä½¿ç”¨ç»Ÿè®¡åŠŸèƒ½")
    
    try:
        test_rate_limiting()
        test_usage_tracking()
        test_log_sanitization()
        test_debug_info()
        test_concurrent_limits()
        test_cost_tracking()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æ²»ç†åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        print("="*60)
        print("\nâœ… æ ¸å¿ƒåŠŸèƒ½:")
        print("1. âœ“ é€Ÿç‡é™åˆ¶ï¼šé˜²æ­¢APIæ»¥ç”¨")
        print("2. âœ“ å¹¶å‘æ§åˆ¶ï¼šé™åˆ¶åŒæ—¶è¯·æ±‚æ•°")
        print("3. âœ“ æˆæœ¬è·Ÿè¸ªï¼šç›‘æ§APIä½¿ç”¨æˆæœ¬")
        print("4. âœ“ ä½¿ç”¨ç»Ÿè®¡ï¼šè®°å½•åˆ°CSVæ–‡ä»¶")
        print("5. âœ“ æ—¥å¿—è„±æ•ï¼šç§»é™¤æ•æ„Ÿä¿¡æ¯")
        print("6. âœ“ è°ƒè¯•ä¿¡æ¯ï¼šå®‰å…¨çš„ç¯å¢ƒä¿¡æ¯")
        
        print("\nğŸ“‹ éªŒæ”¶è¾¾æˆ:")
        print("â€¢ æ—¥å¿—æ— Keyï¼Œllm_usage.csvæ­£å¸¸ç´¯åŠ  âœ…")
        print("â€¢ å¹¶å‘å’Œé€Ÿç‡é™åˆ¶ç”Ÿæ•ˆ âœ…")
        print("â€¢ æˆæœ¬ç›‘æ§å’Œé™åˆ¶ âœ…")
        print("â€¢ æ•æ„Ÿä¿¡æ¯è„±æ• âœ…")
        
        print("\nğŸ”§ é…ç½®è¯´æ˜:")
        print("â€¢ è®¾ç½® DEBUG_LLM=true å¯ç”¨å®Œæ•´æ—¥å¿—")
        print("â€¢ è°ƒæ•´ config.yaml ä¸­çš„ limits é…ç½®")
        print("â€¢ æŸ¥çœ‹ datasets/cache/llm_usage.csv ç»Ÿè®¡")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    main()
