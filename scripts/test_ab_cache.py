#!/usr/bin/env python3
"""
A/Bå¯¹ç…§ä¸ç¼“å­˜å‘½ä¸­æµ‹è¯•è„šæœ¬
"""

import sys
import time
import json
import os
import requests
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from maowise.utils.logger import logger

def test_ab_cache(mode="offline", repeat_count=2):
    """æµ‹è¯•A/Bå¯¹ç…§å’Œç¼“å­˜å‘½ä¸­"""
    
    # è®¾ç½®ç¯å¢ƒ
    if mode == "online":
        if not os.getenv("OPENAI_API_KEY"):
            os.environ["OPENAI_API_KEY"] = "sk-test-key-for-testing"
        logger.info("ğŸŒ åœ¨çº¿æ¨¡å¼å·²å¯ç”¨")
    else:
        if "OPENAI_API_KEY" in os.environ:
            del os.environ["OPENAI_API_KEY"]
        logger.info("ğŸ“´ ç¦»çº¿æ¨¡å¼å·²å¯ç”¨")
    
    base_url = "http://localhost:8000"
    session = requests.Session()
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    try:
        response = session.get(f"{base_url}/api/maowise/v1/health")
        if response.status_code != 200:
            logger.error("APIæœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡")
            return False
        logger.info("âœ… APIæœåŠ¡æ­£å¸¸è¿è¡Œ")
    except Exception as e:
        logger.error(f"æ— æ³•è¿æ¥åˆ°APIæœåŠ¡: {e}")
        return False
    
    # è·å–æµ‹è¯•å‰çš„ä½¿ç”¨ç»Ÿè®¡
    try:
        stats_response = session.get(f"{base_url}/api/maowise/v1/stats/usage")
        stats_before = stats_response.json() if stats_response.status_code == 200 else {}
        logger.info("âœ… è·å–ä½¿ç”¨ç»Ÿè®¡")
    except Exception as e:
        logger.warning(f"è·å–ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
        stats_before = {}
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_description = ("AZ91 substrate; silicate electrolyte: Na2SiO3 10 g/L, KOH 2 g/L; "
                      "bipolar 500 Hz 30% duty; current density 12 A/dm2; time 10 min; "
                      "post-treatment none.")
    
    results = []
    
    # æ‰§è¡Œå¤šæ¬¡ç›¸åŒçš„clarifyè°ƒç”¨
    for i in range(repeat_count):
        logger.info(f"ğŸ“ æ‰§è¡Œç¬¬ {i+1} æ¬¡clarifyè°ƒç”¨...")
        
        payload = {
            "current_data": {},
            "context_description": test_description,
            "max_questions": 3,
            "include_mandatory": True
        }
        
        start_time = time.time()
        response = session.post(f"{base_url}/api/maowise/v1/expert/clarify", json=payload)
        end_time = time.time()
        
        response_time = end_time - start_time
        
        if response.status_code != 200:
            logger.error(f"ç¬¬ {i+1} æ¬¡è°ƒç”¨å¤±è´¥: {response.status_code}")
            continue
        
        result = response.json()
        
        # æ£€æµ‹ç¼“å­˜å‘½ä¸­
        cache_hit = False
        cache_info = {}
        
        # æ£€æŸ¥å“åº”å¤´
        if hasattr(response, 'headers'):
            cache_hit = response.headers.get('X-Cache-Hit', 'false').lower() == 'true'
            cache_info['header_cache_hit'] = cache_hit
        
        # æ£€æŸ¥å“åº”JSONä¸­çš„ç¼“å­˜æ ‡è®°
        try:
            if isinstance(result, dict):
                json_cache_hit = result.get('cache_hit', False)
                cache_info['json_cache_hit'] = json_cache_hit
                cache_hit = cache_hit or json_cache_hit
                
                # æ£€æŸ¥LLMç›¸å…³çš„ç¼“å­˜ä¿¡æ¯
                if 'llm_cache_hit' in result:
                    cache_info['llm_cache_hit'] = result['llm_cache_hit']
                    cache_hit = cache_hit or result['llm_cache_hit']
        except:
            pass
        
        # è®°å½•ç»“æœ
        call_result = {
            "call_number": i + 1,
            "response_time": response_time,
            "cache_hit": cache_hit,
            "cache_info": cache_info,
            "questions_count": len(result.get("questions", [])),
            "status_code": response.status_code,
            "mode": mode
        }
        
        results.append(call_result)
        logger.info(f"ç¬¬ {i+1} æ¬¡è°ƒç”¨å®Œæˆ: å“åº”æ—¶é—´={response_time:.3f}s, ç¼“å­˜å‘½ä¸­={cache_hit}, é—®é¢˜æ•°={len(result.get('questions', []))}")
        
        # çŸ­æš‚å»¶è¿Ÿ
        if i < repeat_count - 1:
            time.sleep(0.5)
    
    # è·å–æµ‹è¯•åçš„ä½¿ç”¨ç»Ÿè®¡
    try:
        stats_response = session.get(f"{base_url}/api/maowise/v1/stats/usage")
        stats_after = stats_response.json() if stats_response.status_code == 200 else {}
    except Exception as e:
        logger.warning(f"è·å–æµ‹è¯•åç»Ÿè®¡å¤±è´¥: {e}")
        stats_after = {}
    
    # è®¡ç®—ç»Ÿè®¡å·®å¼‚
    token_diff = 0
    cost_diff = 0.0
    requests_diff = 0
    
    if stats_after and stats_before:
        token_diff = stats_after.get("total", {}).get("tokens", 0) - stats_before.get("total", {}).get("tokens", 0)
        cost_diff = stats_after.get("total", {}).get("cost", 0.0) - stats_before.get("total", {}).get("cost", 0.0)
        requests_diff = stats_after.get("total", {}).get("requests", 0) - stats_before.get("total", {}).get("requests", 0)
    
    # åˆ†æç»“æœ
    cache_hits = [r["cache_hit"] for r in results]
    cache_hit_rate = sum(cache_hits) / len(cache_hits) if cache_hits else 0
    response_times = [r["response_time"] for r in results]
    avg_response_time = sum(response_times) / len(response_times) if response_times else 0
    
    # ç”ŸæˆæŠ¥å‘Š
    logger.info(f"\nğŸ“Š A/Bå¯¹ç…§æµ‹è¯•æŠ¥å‘Š (æ¨¡å¼: {mode})")
    logger.info("="*50)
    logger.info(f"è°ƒç”¨æ¬¡æ•°: {len(results)}")
    logger.info(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1%}")
    logger.info(f"ç¼“å­˜å‘½ä¸­åºåˆ—: {cache_hits}")
    logger.info(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
    logger.info(f"å“åº”æ—¶é—´åºåˆ—: {[f'{t:.3f}s' for t in response_times]}")
    logger.info(f"Tokenæ¶ˆè€—å·®å¼‚: {token_diff}")
    logger.info(f"æˆæœ¬å·®å¼‚: ${cost_diff:.4f}")
    logger.info(f"è¯·æ±‚æ•°å·®å¼‚: {requests_diff}")
    
    if len(cache_hits) >= 2:
        second_call_cached = cache_hits[1] if len(cache_hits) > 1 else False
        logger.info(f"ç¬¬äºŒæ¬¡è°ƒç”¨ç¼“å­˜å‘½ä¸­: {'âœ… æ˜¯' if second_call_cached else 'âŒ å¦'}")
        
        if len(response_times) >= 2:
            time_improvement = response_times[0] - response_times[1]
            improvement_pct = (time_improvement / response_times[0] * 100) if response_times[0] > 0 else 0
            logger.info(f"å“åº”æ—¶é—´æ”¹å–„: {time_improvement:.3f}s ({improvement_pct:.1f}%)")
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
    report_data = {
        "mode": mode,
        "repeat_count": repeat_count,
        "results": results,
        "cache_hit_rate": cache_hit_rate,
        "avg_response_time": avg_response_time,
        "token_diff": token_diff,
        "cost_diff": cost_diff,
        "requests_diff": requests_diff,
        "stats_before": stats_before,
        "stats_after": stats_after
    }
    
    reports_dir = Path("reports")
    reports_dir.mkdir(exist_ok=True)
    
    report_file = reports_dir / f"ab_cache_test_{mode}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="A/Bå¯¹ç…§ä¸ç¼“å­˜æµ‹è¯•")
    parser.add_argument("--mode", choices=["offline", "online"], default="offline", help="æµ‹è¯•æ¨¡å¼")
    parser.add_argument("--repeat", type=int, default=2, help="é‡å¤æ¬¡æ•°")
    
    args = parser.parse_args()
    
    logger.info(f"ğŸš€ å¼€å§‹A/Bå¯¹ç…§ç¼“å­˜æµ‹è¯•")
    logger.info(f"æ¨¡å¼: {args.mode}, é‡å¤: {args.repeat}æ¬¡")
    
    success = test_ab_cache(args.mode, args.repeat)
    
    if success:
        logger.info("ğŸ‰ A/Bå¯¹ç…§æµ‹è¯•å®Œæˆ")
    else:
        logger.error("âŒ A/Bå¯¹ç…§æµ‹è¯•å¤±è´¥")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
