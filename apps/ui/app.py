# ç¡®ä¿èƒ½æ‰¾åˆ°maowiseåŒ… - è¿è¡Œæ—¶æ³¨å…¥é¡¹ç›®æ ¹ç›®å½•
import sys
import pathlib
REPO_ROOT = pathlib.Path(__file__).resolve().parents[2]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

import streamlit as st
import pandas as pd
import time
from pathlib import Path
from maowise.utils.config import load_config
from maowise.utils.logger import logger
from maowise.dataflow.ingest import main as ingest_main
from maowise.kb.build_index import build_index
from maowise.kb.search import kb_search
from maowise.models.infer_fwd import predict_performance
from maowise.optimize.engines import recommend_solutions


st.set_page_config(page_title="MAO-Wise", layout="wide")
cfg = load_config()


def page_data_center():
    st.header("æ•°æ®ä¸­å¿ƒï¼šä¸Šä¼ ä¸æ„å»º")
    uploaded = st.file_uploader("ä¸Šä¼  PDF", type=["pdf"], accept_multiple_files=True)
    if uploaded:
        out_dir = Path(cfg["paths"]["data_raw"]) 
        out_dir.mkdir(parents=True, exist_ok=True)
        for f in uploaded:
            dest = out_dir / f.name
            with open(dest, "wb") as w:
                w.write(f.read())
        st.success(f"å·²ä¿å­˜ {len(uploaded)} ä¸ª PDF åˆ° {out_dir}")

    if st.button("è¿è¡ŒæŠ½å–ä¸å»ºåº“"):
        stats = ingest_main(cfg["paths"]["data_raw"], f"{cfg['paths']['versions']}/maowise_ds_v1")
        build_index(f"{cfg['paths']['data_parsed']}/corpus.jsonl", cfg["paths"]["index_store"])
        st.json(stats)


def page_predict():
    st.header("æ€§èƒ½é¢„æµ‹ï¼šæ–‡æœ¬ â†’ Î±/Îµ")
    text = st.text_area("è¾“å…¥è‡ªç”±æ–‡æœ¬ï¼ˆå®éªŒæ–¹æ³• + ææ–™ä½“ç³»ï¼‰", height=200)
    if st.button("é¢„æµ‹") and text.strip():
        res = predict_performance(text, topk_cases=3)
        col1, col2, col3 = st.columns(3)
        col1.metric("Î± (150â€“2600nm)", f"{res['alpha']:.3f}")
        col2.metric("Îµ (3000â€“30000nm)", f"{res['epsilon']:.3f}")
        col3.metric("ç½®ä¿¡åº¦", f"{res['confidence']:.2f}")
        
        # æ˜¾ç¤ºè§£é‡Šä¸å¼•ç”¨
        if 'explanation' in res:
            with st.expander("ğŸ’¡ é¢„æµ‹è§£é‡Šä¸æ–‡çŒ®æ”¯æ’‘", expanded=True):
                explanation = res['explanation']
                explanations = explanation.get('explanations', [])
                citation_map = explanation.get('citation_map', {})
                
                st.write("**é¢„æµ‹ä¾æ®:**")
                for j, exp in enumerate(explanations, 1):
                    st.write(f"**{j}.** {exp.get('point', '')}")
                    
                    # æ˜¾ç¤ºå¼•ç”¨
                    citations = exp.get('citations', [])
                    if citations:
                        citation_links = []
                        for cit_id in citations:
                            if cit_id in citation_map:
                                cit_info = citation_map[cit_id]
                                citation_links.append(f"[{cit_id}]({cit_info.get('source', 'Unknown')})")
                        st.markdown(f"*å¼•ç”¨: {', '.join(citation_links)}*")
                    st.write("")
                
                # æ–‡çŒ®è¯¦æƒ…
                if citation_map:
                    with st.expander("ğŸ“š æ”¯æ’‘æ–‡çŒ®è¯¦æƒ…", expanded=False):
                        for cit_id, cit_info in citation_map.items():
                            st.markdown(f"**[{cit_id}]** {cit_info.get('source', 'Unknown')} (é¡µ {cit_info.get('page', 'N/A')})")
                            st.markdown(f"*{cit_info.get('text', '')[:300]}...*")
                            st.markdown(f"*ç›¸å…³æ€§å¾—åˆ†: {cit_info.get('score', 'N/A'):.3f}*")
                            st.write("---")
        
        st.subheader("ç›¸ä¼¼æ¡ˆä¾‹")
        st.dataframe(pd.DataFrame(res.get("nearest_cases", [])))


def page_optimize():
    st.header("åå‘ä¼˜åŒ–ï¼šç›®æ ‡ â†’ å»ºè®®")
    alpha = st.slider("ç›®æ ‡ Î±", 0.0, 1.0, 0.20, 0.01)
    epsilon = st.slider("ç›®æ ‡ Îµ", 0.0, 1.0, 0.80, 0.01)
    current_hint = st.text_area("å½“å‰æ–¹æ¡ˆï¼ˆå¯é€‰ï¼‰", height=120)
    c1, c2 = st.columns(2)
    with c1:
        v_lo, v_hi = st.slider("ç”µå‹èŒƒå›´ (V)", 100, 700, (200, 500))
    with c2:
        t_lo, t_hi = st.slider("æ—¶é—´èŒƒå›´ (min)", 1, 120, (5, 60))
    if st.button("ç”Ÿæˆå»ºè®®"):
        res = recommend_solutions(
            target={"alpha": alpha, "epsilon": epsilon},
            current_hint=current_hint or None,
            constraints={"voltage_V": [v_lo, v_hi], "time_min": [t_lo, t_hi]},
            n_solutions=5,
        )
        sols = res.get("solutions", [])
        st.write(f"è¿”å› {len(sols)} æ¡æ–¹æ¡ˆ")
        
        for i, s in enumerate(sols, 1):
            with st.expander(f"æ–¹æ¡ˆ {i}: {s.get('description', 'N/A')[:50]}...", expanded=i==1):
                # åŸºæœ¬å‚æ•°æ˜¾ç¤º
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**é¢„æœŸæ€§èƒ½:**")
                    st.write(f"- Î±: {s.get('expected_alpha', 'N/A')}")
                    st.write(f"- Îµ: {s.get('expected_epsilon', 'N/A')}")
                    st.write(f"- ç½®ä¿¡åº¦: {s.get('confidence', 'N/A')}")
                
                with col2:
                    st.write("**å…³é”®å‚æ•°:**")
                    if 'voltage_V' in s:
                        st.write(f"- ç”µå‹: {s['voltage_V']} V")
                    if 'current_density_A_dm2' in s:
                        st.write(f"- ç”µæµå¯†åº¦: {s['current_density_A_dm2']} A/dmÂ²")
                    if 'time_min' in s:
                        st.write(f"- æ—¶é—´: {s['time_min']} min")
                
                # è§£é‡Šä¸å¼•ç”¨æŠ˜å åŒº
                if 'explanation' in s:
                    with st.expander("ğŸ’¡ è§£é‡Šä¸å¼•ç”¨", expanded=False):
                        explanation = s['explanation']
                        explanations = explanation.get('explanations', [])
                        citation_map = explanation.get('citation_map', {})
                        
                        st.write("**ä¸“å®¶è§£é‡Š:**")
                        for j, exp in enumerate(explanations, 1):
                            st.write(f"**{j}.** {exp.get('point', '')}")
                            
                            # æ˜¾ç¤ºå¼•ç”¨
                            citations = exp.get('citations', [])
                            if citations:
                                citation_links = []
                                for cit_id in citations:
                                    if cit_id in citation_map:
                                        cit_info = citation_map[cit_id]
                                        citation_links.append(f"[{cit_id}]({cit_info.get('source', 'Unknown')})")
                                st.markdown(f"*å¼•ç”¨: {', '.join(citation_links)}*")
                            st.write("")
                        
                        # æ–‡çŒ®è¯¦æƒ…
                        if citation_map:
                            with st.expander("ğŸ“š å¼•ç”¨æ–‡çŒ®è¯¦æƒ…", expanded=False):
                                for cit_id, cit_info in citation_map.items():
                                    st.markdown(f"**[{cit_id}]** {cit_info.get('source', 'Unknown')} (é¡µ {cit_info.get('page', 'N/A')})")
                                    st.markdown(f"*{cit_info.get('text', '')[:300]}...*")
                                    st.markdown(f"*ç›¸å…³æ€§å¾—åˆ†: {cit_info.get('score', 'N/A'):.3f}*")
                                    st.write("---")
                
                # å·¥è‰ºå¡æŠ˜å åŒº
                if 'plan_yaml' in s:
                    with st.expander("ğŸ“‹ å¯æ‰§è¡Œå·¥è‰ºå¡", expanded=False):
                        yaml_content = s['plan_yaml']
                        
                        # æ˜¾ç¤ºçº¦æŸæ£€æŸ¥ç»“æœ
                        if s.get('hard_constraints_passed', True):
                            st.success("âœ… é€šè¿‡ç¡¬çº¦æŸæ£€æŸ¥")
                        else:
                            st.error("âŒ æœªé€šè¿‡ç¡¬çº¦æŸæ£€æŸ¥ï¼Œè¯·è°ƒæ•´å‚æ•°")
                        
                        # æ˜¾ç¤ºYAMLå†…å®¹
                        st.code(yaml_content, language='yaml')
                        
                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label=f"ğŸ“¥ ä¸‹è½½æ–¹æ¡ˆ{i}å·¥è‰ºå¡ (.yaml)",
                            data=yaml_content,
                            file_name=f"mao_process_plan_{i}.yaml",
                            mime="text/yaml",
                            help="ä¸‹è½½å¯æ‰§è¡Œçš„å·¥è‰ºå¡æ–‡ä»¶"
                        )
                        
                        # å·¥è‰ºå¡å¼•ç”¨
                        if 'plan_citations' in s and s['plan_citations']:
                            st.write("**å·¥è‰ºå¡æ–‡çŒ®æ”¯æ’‘:**")
                            for cit_id, cit_info in s['plan_citations'].items():
                                st.markdown(f"**[{cit_id}]** {cit_info.get('source', 'Unknown')} (é¡µ {cit_info.get('page', 'N/A')})")
                
                # åŸå§‹JSONæ•°æ®ï¼ˆè°ƒè¯•ç”¨ï¼‰
                with st.expander("ğŸ”§ åŸå§‹æ•°æ®", expanded=False):
                    st.json(s)
        df = pd.DataFrame([
            {"æ–¹æ¡ˆ": i + 1, "Î±": s["predicted"]["alpha"], "Îµ": s["predicted"]["epsilon"]}
            for i, s in enumerate(sols)
        ])
        if not df.empty:
            st.bar_chart(df.set_index("æ–¹æ¡ˆ"))
        import json as _json
        st.download_button("å¯¼å‡ºJSON", data=_json.dumps(res, ensure_ascii=False, indent=2), file_name="recommendations.json")


def page_kb():
    st.header("çŸ¥è¯†æ£€ç´¢")
    q = st.text_input("æŸ¥è¯¢")
    if st.button("æ£€ç´¢") and q.strip():
        hits = kb_search(q, k=5)
        st.dataframe(pd.DataFrame(hits))


def page_expert_qa():
    st.header("ä¸“å®¶é—®ç­”ç³»ç»Ÿ")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "expert_thread" not in st.session_state:
        st.session_state.expert_thread = {
            "questions": [],
            "answers": {},
            "current_question_idx": 0,
            "status": "active",
            "thread_id": f"thread_{int(time.time())}"
        }
    
    thread = st.session_state.expert_thread
    
    # æ˜¾ç¤ºè¿›åº¦
    if thread["questions"]:
        progress = len([q for q in thread["questions"] if thread["answers"].get(q["id"])]) / len(thread["questions"])
        st.progress(progress, text=f"é—®é¢˜è¿›åº¦: {int(progress*100)}%")
    
    # ç”Ÿæˆåˆå§‹é—®é¢˜æŒ‰é’®
    if not thread["questions"]:
        st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹ä¸“å®¶å’¨è¯¢æµç¨‹")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ” ç”Ÿæˆå¿…ç­”é—®é¢˜", type="primary"):
                try:
                    from maowise.experts.clarify import generate_clarify_questions
                    
                    questions = generate_clarify_questions(
                        current_data={},
                        context_description="ä¸“å®¶å’¨è¯¢",
                        max_questions=5,
                        include_mandatory=True
                    )
                    
                    thread["questions"] = [q.model_dump() for q in questions]
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"ç”Ÿæˆé—®é¢˜å¤±è´¥: {e}")
        
        with col2:
            if st.button("ğŸ“‹ æŸ¥çœ‹é—®é¢˜æ¸…å•"):
                try:
                    from maowise.experts.followups import load_question_catalog
                    catalog = load_question_catalog()
                    mandatory_qs = catalog.get("mandatory_questions", [])
                    
                    st.write("**å¿…ç­”é—®é¢˜æ¸…å•:**")
                    for i, q in enumerate(mandatory_qs, 1):
                        priority_icon = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(q.get("priority", "medium"), "ğŸŸ¡")
                        st.write(f"{priority_icon} **{i}.** {q['question']}")
                        st.write(f"   *{q['rationale']}*")
                        st.write("")
                        
                except Exception as e:
                    st.error(f"åŠ è½½é—®é¢˜æ¸…å•å¤±è´¥: {e}")
        return
    
    # æ˜¾ç¤ºé—®é¢˜å’Œå›ç­”
    for i, question in enumerate(thread["questions"]):
        question_id = question["id"]
        
        # é—®é¢˜æ ‡é¢˜å’Œæ ‡è®°
        col1, col2, col3 = st.columns([0.7, 0.2, 0.1])
        
        with col1:
            # ä¼˜å…ˆçº§å’Œç±»å‹æ ‡è®°
            priority_icon = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(question.get("priority", "medium"), "ğŸŸ¡")
            mandatory_mark = "â­" if question.get("is_mandatory") else ""
            followup_mark = "ğŸ”„" if question.get("is_followup") else ""
            
            st.markdown(f"### {priority_icon} {mandatory_mark} {followup_mark} é—®é¢˜ {i+1}")
            st.write(question["question"])
            st.caption(f"ğŸ’¡ {question.get('rationale', '')}")
        
        with col2:
            # çŠ¶æ€æŒ‡ç¤º
            if question_id in thread["answers"] and thread["answers"][question_id].strip():
                st.success("âœ… å·²å›ç­”")
            else:
                if question.get("is_mandatory"):
                    st.error("â— å¿…ç­”")
                else:
                    st.warning("â³ å¾…å›ç­”")
        
        with col3:
            # æ“ä½œæŒ‰é’®
            if question.get("is_followup"):
                st.caption("è¿½é—®")
        
        # å›ç­”è¾“å…¥åŒºåŸŸ
        current_answer = thread["answers"].get(question_id, "")
        
        if question.get("kind") == "choice" and question.get("options"):
            # é€‰æ‹©é¢˜
            options = question["options"]
            current_idx = 0
            if current_answer in options:
                current_idx = options.index(current_answer)
            
            selected = st.selectbox(
                f"è¯·é€‰æ‹© (é—®é¢˜ {i+1})",
                options,
                index=current_idx,
                key=f"select_{question_id}"
            )
            
            if selected != current_answer:
                thread["answers"][question_id] = selected
                st.rerun()
                
        else:
            # æ–‡æœ¬è¾“å…¥
            answer = st.text_area(
                f"è¯·å›ç­” (é—®é¢˜ {i+1})",
                value=current_answer,
                height=100,
                key=f"answer_{question_id}"
            )
            
            if answer != current_answer:
                thread["answers"][question_id] = answer
        
        # è¿½é—®é€»è¾‘
        if (question_id in thread["answers"] and 
            thread["answers"][question_id].strip() and 
            not question.get("is_followup")):
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿½é—®
            try:
                from maowise.experts.followups import is_answer_vague, load_question_catalog
                
                catalog = load_question_catalog()
                mandatory_qs = catalog.get("mandatory_questions", [])
                q_config = next((q for q in mandatory_qs if q["id"] == question_id), None)
                
                if q_config and is_answer_vague(thread["answers"][question_id], q_config):
                    col_followup1, col_followup2 = st.columns([0.7, 0.3])
                    
                    with col_followup1:
                        st.warning(f"âš ï¸ å›ç­”'{thread['answers'][question_id]}'è¿‡äºå«ç³Š")
                    
                    with col_followup2:
                        if st.button(f"ğŸ”„ ä¸€é”®è¿½é—®", key=f"followup_{question_id}"):
                            # ç”Ÿæˆè¿½é—®
                            try:
                                from maowise.experts.clarify import generate_clarify_questions
                                
                                followup_questions = generate_clarify_questions(
                                    current_data={},
                                    expert_answers={question_id: thread["answers"][question_id]},
                                    max_questions=1,
                                    include_mandatory=False
                                )
                                
                                if followup_questions:
                                    # æ·»åŠ è¿½é—®åˆ°é—®é¢˜åˆ—è¡¨
                                    new_q = followup_questions[0].model_dump()
                                    thread["questions"].insert(i+1, new_q)
                                    st.rerun()
                                    
                            except Exception as e:
                                st.error(f"ç”Ÿæˆè¿½é—®å¤±è´¥: {e}")
                                
            except Exception as e:
                st.caption(f"è¿½é—®æ£€æŸ¥å¤±è´¥: {e}")
        
        st.divider()
    
    # åº•éƒ¨æ“ä½œ
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆé—®é¢˜"):
            thread["questions"] = []
            thread["answers"] = {}
            st.rerun()
    
    with col2:
        # æ£€æŸ¥å®ŒæˆçŠ¶æ€
        answered_count = len([q for q in thread["questions"] if thread["answers"].get(q["id"], "").strip()])
        mandatory_count = len([q for q in thread["questions"] if q.get("is_mandatory")])
        mandatory_answered = len([q for q in thread["questions"] 
                                if q.get("is_mandatory") and thread["answers"].get(q["id"], "").strip()])
        
        if mandatory_answered == mandatory_count and answered_count > 0:
            if st.button("âœ… å®Œæˆé—®ç­”å¹¶ç»§ç»­", type="primary"):
                thread["status"] = "resolved"
                st.success("âœ… ä¸“å®¶é—®ç­”å®Œæˆï¼å¯ä»¥ç»§ç»­è¿›è¡Œé¢„æµ‹æˆ–ä¼˜åŒ–ã€‚")
                
                # æ˜¾ç¤ºæ”¶é›†åˆ°çš„ä¿¡æ¯
                with st.expander("ğŸ“‹ æ”¶é›†åˆ°çš„ä¿¡æ¯", expanded=True):
                    for question in thread["questions"]:
                        if thread["answers"].get(question["id"], "").strip():
                            st.write(f"**{question['question']}**")
                            st.write(f"å›ç­”: {thread['answers'][question['id']]}")
                            st.write("")
        else:
            st.info(f"å¿…ç­”é—®é¢˜è¿›åº¦: {mandatory_answered}/{mandatory_count}")
    
    with col3:
        if st.button("ğŸ“Š éªŒè¯å›ç­”è´¨é‡"):
            try:
                from maowise.experts.followups import validate_mandatory_answers
                
                validation = validate_mandatory_answers(thread["answers"])
                
                if validation["all_answered"] and validation["all_specific"]:
                    st.success("âœ… æ‰€æœ‰å›ç­”éƒ½ç¬¦åˆè¦æ±‚")
                else:
                    if validation["missing_questions"]:
                        st.error(f"âŒ {len(validation['missing_questions'])} ä¸ªå¿…ç­”é—®é¢˜æœªå›ç­”")
                    
                    if validation["vague_answers"]:
                        st.warning(f"âš ï¸ {len(validation['vague_answers'])} ä¸ªå›ç­”è¿‡äºå«ç³Š")
                        
                    if validation["needs_followup"]:
                        st.info(f"ğŸ”„ éœ€è¦ {len(validation['needs_followup'])} ä¸ªè¿½é—®")
                        
            except Exception as e:
                st.error(f"éªŒè¯å¤±è´¥: {e}")


def page_llm_chat():
    st.header("LLM èŠå¤©åŠ©æ‰‹")
    
    # é…ç½®é€‰é¡¹
    col1, col2 = st.columns(2)
    with col1:
        use_rag = st.checkbox("ä½¿ç”¨ RAGï¼ˆçŸ¥è¯†æ£€ç´¢å¢å¼ºï¼‰", value=True)
    with col2:
        provider = st.selectbox("LLM æä¾›å•†", ["local", "openai", "azure"], index=0)
    
    # ç³»ç»Ÿæç¤º
    system_prompt = st.text_area(
        "ç³»ç»Ÿæç¤º", 
        value="ä½ æ˜¯å¾®å¼§æ°§åŒ–ç ”ç©¶çš„ä¸“ä¸šåŠ©æ‰‹ï¼Œè¯·åŸºäºæä¾›çš„æ–‡çŒ®å†…å®¹å›ç­”é—®é¢˜ã€‚",
        height=100
    )
    
    # èŠå¤©ç•Œé¢
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # è°ƒç”¨ LLM
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                try:
                    from maowise.llm.client import llm_chat
                    from maowise.llm.rag import build_rag_prompt
                    
                    if use_rag:
                        messages = build_rag_prompt(prompt, system_prompt)
                    else:
                        messages = [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": prompt}
                        ]
                    
                    response = llm_chat(messages)
                    content = response.get("content", "")
                    usage = response.get("usage", {})
                    
                    st.markdown(content)
                    
                    # æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡
                    if usage.get("total_tokens", 0) > 0:
                        st.caption(f"Token ä½¿ç”¨: {usage.get('total_tokens', 0)} (æç¤º: {usage.get('prompt_tokens', 0)}, å®Œæˆ: {usage.get('completion_tokens', 0)})")
                    
                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                    st.session_state.messages.append({"role": "assistant", "content": content})
                    
                except Exception as e:
                    error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
    
    # æ¸…é™¤èŠå¤©å†å²æŒ‰é’®
    if st.button("æ¸…é™¤èŠå¤©å†å²"):
        st.session_state.messages = []
        st.rerun()


def page_feedback():
    st.header("åé¦ˆ")
    rating = st.slider("è¯„åˆ†", 1, 5, 4)
    note = st.text_area("å¤‡æ³¨", height=120)
    if st.button("æäº¤"):
        fb_file = Path(cfg["paths"]["versions"]) / "feedback.parquet"
        df = pd.DataFrame([[rating, note]], columns=["rating", "note"])
        if fb_file.exists():
            old = pd.read_parquet(fb_file)
            df = pd.concat([old, df], ignore_index=True)
        df.to_parquet(fb_file, index=False)
        st.success("å·²è®°å½•åé¦ˆ")


PAGES = {
    "æ•°æ®ä¸­å¿ƒ": page_data_center,
    "æ€§èƒ½é¢„æµ‹": page_predict,
    "ä¼˜åŒ–å»ºè®®": page_optimize,
    "çŸ¥è¯†æ£€ç´¢": page_kb,
    "ä¸“å®¶é—®ç­”": page_expert_qa,
    "LLM èŠå¤©": page_llm_chat,
    "åé¦ˆ": page_feedback,
}

choice = st.sidebar.radio("é¡µé¢", list(PAGES.keys()))
PAGES[choice]()

